'use client';

import { useState, useRef, useCallback } from 'react';
import { Button } from '@/components/ui/button';
import { Mic, MicOff, Loader2 } from 'lucide-react';

interface VoiceInputProps {
  onTranscript: (text: string) => void;
  onError?: (error: string) => void;
  disabled?: boolean;
}

export function VoiceInput({ onTranscript, onError, disabled = false }: VoiceInputProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const mediaRecorderRef = useRef<any>(null);
  const audioChunksRef = useRef<Blob[]>([]);

  // å¼€å§‹å½•éŸ³
  const startRecording = useCallback(async () => {
    try {
      // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
      if (!navigator || !('mediaDevices' in navigator) || !navigator.mediaDevices.getUserMedia) {
        onError?.('æµè§ˆå™¨ä¸æ”¯æŒå½•éŸ³åŠŸèƒ½');
        return;
      }

      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 16000
        } 
      });

      // æ£€æŸ¥MediaRecorderæ”¯æŒ
      if (typeof window !== 'undefined' && 'MediaRecorder' in window) {
        const mediaRecorder = new (window as any).MediaRecorder(stream, {
          mimeType: 'audio/webm;codecs=opus'
        });

        mediaRecorderRef.current = mediaRecorder;
        audioChunksRef.current = [];

        mediaRecorder.ondataavailable = (event: any) => {
          if (event.data.size > 0) {
            audioChunksRef.current.push(event.data);
          }
        };

        mediaRecorder.onstop = async () => {
          const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
          await processAudio(audioBlob);
          
          // åœæ­¢æ‰€æœ‰éŸ³é¢‘è½¨é“
          stream.getTracks().forEach((track: any) => track.stop());
        };

        mediaRecorder.start(1000);
        setIsRecording(true);
      } else {
        onError?.('æµè§ˆå™¨ä¸æ”¯æŒMediaRecorder');
      }
    } catch (error) {
      console.error('Error starting recording:', error);
      onError?.('æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®');
    }
  }, [onError]);

  // åœæ­¢å½•éŸ³
  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      setIsProcessing(true);
    }
  }, [isRecording]);

  // å¤„ç†éŸ³é¢‘
  const processAudio = async (audioBlob: Blob) => {
    try {
      // è½¬æ¢ä¸ºbase64
      const base64Audio = await blobToBase64(audioBlob);
      
      // å‘é€åˆ°ASR API
      const response = await fetch('/api/multimodal/asr', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          audioData: base64Audio.split(',')[1], // ç§»é™¤data:audio/webm;base64,å‰ç¼€
          provider: 'mock',
          language: 'zh-CN'
        }),
      });

      const result = await response.json() as any;
      
      if (result.success && result.data?.text) {
        console.log(`ğŸ¯ è¯­éŸ³è¯†åˆ«æˆåŠŸ: "${result.data.text}" (ç½®ä¿¡åº¦: ${(result.data.confidence * 100).toFixed(1)}%)`);
        onTranscript(result.data.text);
      } else {
        const errorMsg = result.suggestion ? 
          `${result.error}\nğŸ’¡ ${result.suggestion}` : 
          result.error || 'è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•';
        onError?.(errorMsg);
      }
    } catch (error) {
      console.error('Error processing audio:', error);
      onError?.('è¯­éŸ³å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥åé‡è¯•');
    } finally {
      setIsProcessing(false);
    }
  };

  // Blobè½¬Base64
  const blobToBase64 = (blob: Blob): Promise<string> => {
    return new Promise((resolve, reject) => {
      if (typeof window !== 'undefined' && 'FileReader' in window) {
        const reader = new FileReader();
        reader.onload = () => resolve(reader.result as string);
        reader.onerror = reject;
        reader.readAsDataURL(blob);
      } else {
        reject(new Error('FileReader not supported'));
      }
    });
  };

  // åˆ‡æ¢å½•éŸ³çŠ¶æ€
  const toggleRecording = () => {
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  };

  return (
    <div className="flex flex-col sm:flex-row items-center gap-2">
      <div className="relative">
        <Button
          variant={isRecording ? "destructive" : "outline"}
          size="icon"
          onClick={toggleRecording}
          disabled={disabled || isProcessing}
          className={`relative h-10 w-10 md:h-12 md:w-12 ${isRecording ? 'bg-red-500 hover:bg-red-600' : ''}`}
        >
          {isProcessing ? (
            <Loader2 className="h-4 w-4 md:h-5 md:w-5 animate-spin" />
          ) : isRecording ? (
            <MicOff className="h-4 w-4 md:h-5 md:w-5" />
          ) : (
            <Mic className="h-4 w-4 md:h-5 md:w-5" />
          )}
          
          {/* å½•éŸ³åŠ¨ç”»æ•ˆæœ */}
          {isRecording && (
            <div className="absolute inset-0 rounded-md border-2 border-red-400 animate-pulse" />
          )}
        </Button>
      </div>

      {/* çŠ¶æ€æŒ‡ç¤º */}
      <div className="flex-1 min-w-0">
        {isRecording && (
          <div className="flex items-center gap-2 text-sm text-red-600">
            <div className="flex gap-1">
              {[0, 1, 2].map((i) => (
                <div
                  key={i}
                  className="w-1 h-3 md:h-4 bg-red-500 rounded-full animate-pulse"
                  style={{ animationDelay: `${i * 0.2}s` }}
                />
              ))}
            </div>
            <span className="truncate">æ­£åœ¨å½•éŸ³...</span>
          </div>
        )}

        {isProcessing && (
          <div className="text-sm text-blue-600">
            æ­£åœ¨è¯†åˆ«...
          </div>
        )}
      </div>
    </div>
  );
}