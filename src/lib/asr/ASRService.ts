// è¯­éŸ³è¯†åˆ«æœåŠ¡ç±»
// æ”¯æŒå¤šç§ASRæä¾›å•†çš„ç»Ÿä¸€æ¥å£

export interface ASRConfig {
  provider: 'mock' | 'openai' | 'baidu' | 'aliyun' | 'tencent';
  apiKey?: string;
  region?: string;
  language?: string;
  model?: string;
}

export interface ASRResult {
  text: string;
  confidence: number;
  language: string;
  duration?: number;
  processingTime: number;
  alternatives?: Array<{
    text: string;
    confidence: number;
  }>;
}

export class ASRService {
  private config: ASRConfig;

  constructor(config: ASRConfig) {
    this.config = config;
  }

  async transcribe(audioData: string): Promise<ASRResult> {
    const startTime = Date.now();

    try {
      let result: ASRResult;

      switch (this.config.provider) {
        case 'openai':
          result = await this.transcribeWithOpenAI(audioData);
          break;
        case 'baidu':
          result = await this.transcribeWithBaidu(audioData);
          break;
        case 'aliyun':
          result = await this.transcribeWithAliyun(audioData);
          break;
        case 'tencent':
          result = await this.transcribeWithTencent(audioData);
          break;
        case 'mock':
        default:
          result = await this.transcribeWithMock(audioData);
          break;
      }

      result.processingTime = Date.now() - startTime;
      return result;

    } catch (error) {
      console.error(`ASR transcription failed with ${this.config.provider}:`, error);
      
      // é™çº§åˆ°æ¨¡æ‹ŸæœåŠ¡
      if (this.config.provider !== 'mock') {
        console.log('ğŸ”„ é™çº§åˆ°æ¨¡æ‹ŸASRæœåŠ¡');
        const mockService = new ASRService({ provider: 'mock' });
        return await mockService.transcribe(audioData);
      }
      
      throw error;
    }
  }

  // OpenAI Whisper API
  private async transcribeWithOpenAI(audioData: string): Promise<ASRResult> {
    if (!this.config.apiKey) {
      throw new Error('OpenAI API key is required');
    }

    // å°†base64è½¬æ¢ä¸ºBlob
    const audioBlob = this.base64ToBlob(audioData, 'audio/webm');
    
    const formData = new FormData();
    formData.append('file', audioBlob, 'audio.webm');
    formData.append('model', this.config.model || 'whisper-1');
    formData.append('language', this.config.language || 'zh');
    formData.append('response_format', 'verbose_json');

    const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.config.apiKey}`,
      },
      body: formData,
    });

    if (!response.ok) {
      throw new Error(`OpenAI API error: ${response.status}`);
    }

    const data = await response.json();
    
    return {
      text: data.text,
      confidence: data.segments?.[0]?.avg_logprob ? Math.exp(data.segments[0].avg_logprob) : 0.9,
      language: data.language || 'zh',
      duration: data.duration,
      processingTime: 0, // å°†åœ¨å¤–å±‚è®¾ç½®
      alternatives: data.segments?.slice(1, 4).map((seg: any) => ({
        text: seg.text,
        confidence: Math.exp(seg.avg_logprob || -1)
      }))
    };
  }

  // ç™¾åº¦è¯­éŸ³è¯†åˆ«API
  private async transcribeWithBaidu(audioData: string): Promise<ASRResult> {
    // è¿™é‡Œåº”è¯¥å®ç°ç™¾åº¦è¯­éŸ³è¯†åˆ«APIè°ƒç”¨
    // ç”±äºéœ€è¦å¤æ‚çš„è®¤è¯æµç¨‹ï¼Œè¿™é‡Œæä¾›æ¡†æ¶
    
    console.log('ğŸ”§ ç™¾åº¦ASRæœåŠ¡éœ€è¦é…ç½®APIå¯†é’¥å’Œè®¤è¯');
    
    // é™çº§åˆ°æ¨¡æ‹ŸæœåŠ¡
    return await this.transcribeWithMock(audioData);
  }

  // é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«API
  private async transcribeWithAliyun(audioData: string): Promise<ASRResult> {
    // è¿™é‡Œåº”è¯¥å®ç°é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«APIè°ƒç”¨
    console.log('ğŸ”§ é˜¿é‡Œäº‘ASRæœåŠ¡éœ€è¦é…ç½®APIå¯†é’¥å’Œè®¤è¯');
    
    // é™çº§åˆ°æ¨¡æ‹ŸæœåŠ¡
    return await this.transcribeWithMock(audioData);
  }

  // è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«API
  private async transcribeWithTencent(audioData: string): Promise<ASRResult> {
    // è¿™é‡Œåº”è¯¥å®ç°è…¾è®¯äº‘è¯­éŸ³è¯†åˆ«APIè°ƒç”¨
    console.log('ğŸ”§ è…¾è®¯äº‘ASRæœåŠ¡éœ€è¦é…ç½®APIå¯†é’¥å’Œè®¤è¯');
    
    // é™çº§åˆ°æ¨¡æ‹ŸæœåŠ¡
    return await this.transcribeWithMock(audioData);
  }

  // æ¨¡æ‹ŸASRæœåŠ¡ - ç”¨äºå¼€å‘å’Œæµ‹è¯•
  private async transcribeWithMock(audioData: string): Promise<ASRResult> {
    // æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
    await new Promise(resolve => setTimeout(resolve, 100 + Math.random() * 300));

    const audioLength = audioData.length;
    
    // æ™ºèƒ½æ¨¡æ‹Ÿç»“æœç”Ÿæˆ
    const mockResults = this.generateMockResults(audioLength);
    const selectedResult = mockResults[Math.floor(Math.random() * mockResults.length)];

    return {
      text: selectedResult.text,
      confidence: selectedResult.confidence,
      language: 'zh-CN',
      duration: this.estimateAudioDuration(audioLength),
      processingTime: 0, // å°†åœ¨å¤–å±‚è®¾ç½®
      alternatives: mockResults.slice(1, 4).map(result => ({
        text: result.text,
        confidence: result.confidence * 0.8 // å¤‡é€‰ç»“æœç½®ä¿¡åº¦ç¨ä½
      }))
    };
  }

  // ç”Ÿæˆæ™ºèƒ½æ¨¡æ‹Ÿç»“æœ
  private generateMockResults(audioLength: number): Array<{text: string, confidence: number}> {
    const shortPhrases = [
      { text: "ä½ å¥½", confidence: 0.98 },
      { text: "è°¢è°¢", confidence: 0.97 },
      { text: "è¯·é—®", confidence: 0.96 },
      { text: "å¸®æˆ‘", confidence: 0.95 },
      { text: "å¥½çš„", confidence: 0.99 }
    ];

    const mediumQuestions = [
      { text: "ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹åŒºå—é“¾æŠ€æœ¯", confidence: 0.92 },
      { text: "è¯·å¸®æˆ‘åˆ†æè¿™ä¸ªå•†ä¸šæ¨¡å¼", confidence: 0.90 },
      { text: "Web4.0çš„å‘å±•å‰æ™¯å¦‚ä½•", confidence: 0.88 },
      { text: "å¦‚ä½•æ„å»ºå¯æŒç»­çš„å•†ä¸šæ¨¡å¼", confidence: 0.91 },
      { text: "äººå·¥æ™ºèƒ½æœ‰å“ªäº›åº”ç”¨åœºæ™¯", confidence: 0.89 }
    ];

    const longQuestions = [
      { text: "ä½ å¥½ï¼Œæˆ‘æƒ³äº†è§£ä¸€ä¸‹åŒºå—é“¾æŠ€æœ¯åœ¨é‡‘èé¢†åŸŸçš„åº”ç”¨å‰æ™¯å’Œå‘å±•è¶‹åŠ¿", confidence: 0.85 },
      { text: "è¯·å¸®æˆ‘è¯¦ç»†åˆ†æä¸€ä¸‹è¿™ä¸ªå•†ä¸šæ¨¡å¼çš„å¯è¡Œæ€§ï¼ŒåŒ…æ‹¬å¸‚åœºå‰æ™¯å’Œé£é™©è¯„ä¼°", confidence: 0.83 },
      { text: "Web4.0æ—¶ä»£ç”¨æˆ·ä¸»æƒçš„é‡è¦æ€§ä½“ç°åœ¨å“ªäº›æ–¹é¢ï¼Œå¯¹ä¼ ç»Ÿäº’è”ç½‘æ¨¡å¼æœ‰ä»€ä¹ˆå½±å“", confidence: 0.87 },
      { text: "å¦‚ä½•æ„å»ºä¸€ä¸ªå¯æŒç»­å‘å±•çš„åˆ›ä¸šé¡¹ç›®ï¼Œéœ€è¦è€ƒè™‘å“ªäº›å…³é”®å› ç´ å’Œæ½œåœ¨é£é™©", confidence: 0.84 },
      { text: "äººå·¥æ™ºèƒ½åœ¨å•†ä¸šåº”ç”¨ä¸­æœ‰å“ªäº›åˆ›æ–°æœºä¼šï¼Œç‰¹åˆ«æ˜¯åœ¨æ•°æ®åˆ†æå’Œå†³ç­–æ”¯æŒæ–¹é¢", confidence: 0.86 }
    ];

    if (audioLength < 5000) {
      return shortPhrases;
    } else if (audioLength < 15000) {
      return mediumQuestions;
    } else {
      return longQuestions;
    }
  }

  // ä¼°ç®—éŸ³é¢‘æ—¶é•¿
  private estimateAudioDuration(audioLength: number): number {
    // åŸºäºbase64é•¿åº¦ä¼°ç®—éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    // è¿™æ˜¯ä¸€ä¸ªç²—ç•¥çš„ä¼°ç®—ï¼Œå®é™…åº”è¯¥è§£æéŸ³é¢‘æ–‡ä»¶
    return Math.max(1, Math.min(60, audioLength / 8000));
  }

  // Base64è½¬Blob
  private base64ToBlob(base64: string, mimeType: string): Blob {
    const byteCharacters = atob(base64);
    const byteNumbers = new Array(byteCharacters.length);
    
    for (let i = 0; i < byteCharacters.length; i++) {
      byteNumbers[i] = byteCharacters.charCodeAt(i);
    }
    
    const byteArray = new Uint8Array(byteNumbers);
    return new Blob([byteArray], { type: mimeType });
  }

  // éªŒè¯éŸ³é¢‘æ ¼å¼
  static validateAudioData(audioData: string): boolean {
    if (!audioData || typeof audioData !== 'string') {
      return false;
    }

    // æ£€æŸ¥base64æ ¼å¼
    try {
      atob(audioData);
      return true;
    } catch {
      return false;
    }
  }

  // è·å–æ”¯æŒçš„é…ç½®
  static getSupportedConfigs(): ASRConfig[] {
    return [
      {
        provider: 'mock',
        language: 'zh-CN'
      },
      {
        provider: 'openai',
        language: 'zh',
        model: 'whisper-1'
      },
      {
        provider: 'baidu',
        language: 'zh-CN'
      },
      {
        provider: 'aliyun',
        language: 'zh-CN'
      },
      {
        provider: 'tencent',
        language: 'zh-CN'
      }
    ];
  }
}